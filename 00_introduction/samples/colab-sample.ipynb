{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ğŸŒ¸ Your First ML Model in Google Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/CS-6140-ML-Learning-Sessions/Machine-Learning-101/blob/main/00_introduction/samples/colab-sample.ipynb)\n",
    "\n",
    "**What you'll build**: A flower species classifier that predicts iris flowers from measurements.\n",
    "\n",
    "**How to use**:\n",
    "1. Click \"Open in Colab\" above\n",
    "2. Save a copy: File â†’ Save a copy in Drive\n",
    "3. Run each cell: Click â–¶ï¸ or press Shift + Enter\n",
    "\n",
    "**Time needed**: 5-10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1"
   },
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "imports"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported!\n",
      "ğŸš€ Ready to build your ML model!\n"
     ]
    }
   ],
   "source": [
    "# Import what we need\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"âœ… Libraries imported!\")\n",
    "print(\"ğŸš€ Ready to build your ML model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2"
   },
   "source": [
    "## Step 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "load_data"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ¸ Loading iris flower dataset...\n",
      "ğŸ“Š Loaded 150 flower samples\n",
      "ğŸ·ï¸ Species: [np.str_('setosa'), np.str_('versicolor'), np.str_('virginica')]\n",
      "ğŸ“ Features: sepal length, sepal width, petal length, petal width\n"
     ]
    }
   ],
   "source": [
    "# Load flower data\n",
    "print(\"ğŸŒ¸ Loading iris flower dataset...\")\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "print(f\"ğŸ“Š Loaded {len(X)} flower samples\")\n",
    "print(f\"ğŸ·ï¸ Species: {list(data.target_names)}\")\n",
    "print(f\"ğŸ“ Features: sepal length, sepal width, petal length, petal width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3"
   },
   "source": [
    "## Step 3: Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "split_data"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Training set: 105 flowers\n",
      "ğŸ§ª Test set: 45 flowers\n"
     ]
    }
   ],
   "source": [
    "# Split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"ğŸ“š Training set: {len(X_train)} flowers\")\n",
    "print(f\"ğŸ§ª Test set: {len(X_test)} flowers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4"
   },
   "source": [
    "## Step 4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "train_model"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Training machine learning model...\n",
      "âœ… Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create and train the model\n",
    "print(\"ğŸ¤– Training machine learning model...\")\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"âœ… Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5"
   },
   "source": [
    "## Step 5: Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "test_model"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Model accuracy: 100.0%\n",
      "ğŸ“Š Great! The model can identify flower species!\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"ğŸ¯ Model accuracy: {accuracy:.1%}\")\n",
    "print(\"ğŸ“Š Great! The model can identify flower species!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step6"
   },
   "source": [
    "## Step 6: Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "predict"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”® Predicting new flowers...\n",
      "ğŸŒº Flower 1: [5.1 3.5 1.4 0.2] â†’ setosa\n",
      "ğŸŒº Flower 2: [6.2 2.8 4.8 1.8] â†’ virginica\n",
      "ğŸŒº Flower 3: [5.7 2.8 4.1 1.3] â†’ versicolor\n",
      "\n",
      "âœ¨ Success! Your ML model is working!\n"
     ]
    }
   ],
   "source": [
    "# Try predicting new flowers\n",
    "print(\"ğŸ”® Predicting new flowers...\")\n",
    "\n",
    "new_flowers = np.array([\n",
    "    [5.1, 3.5, 1.4, 0.2],  # Small petals\n",
    "    [6.2, 2.8, 4.8, 1.8],  # Large petals\n",
    "    [5.7, 2.8, 4.1, 1.3]   # Medium petals\n",
    "])\n",
    "\n",
    "predictions = model.predict(new_flowers)\n",
    "\n",
    "for i, (flower, pred) in enumerate(zip(new_flowers, predictions)):\n",
    "    species = data.target_names[pred]\n",
    "    print(f\"ğŸŒº Flower {i+1}: {flower} â†’ {species}\")\n",
    "\n",
    "print(\"\\nâœ¨ Success! Your ML model is working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab_tip"
   },
   "source": [
    "## ğŸš€ Colab Tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "colab_features"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ PyTorch not installed (that's okay for this example!)\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "try:\n",
    "    import torch\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    print(f\"ğŸ”¥ GPU available: {gpu_available}\")\n",
    "    if not gpu_available:\n",
    "        print(\"ğŸ’¡ Enable GPU: Runtime â†’ Change runtime type â†’ GPU\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ PyTorch not installed (that's okay for this example!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## ğŸ‰ Congratulations!\n",
    "\n",
    "You built your first ML model in Google Colab!\n",
    "\n",
    "### What you learned:\n",
    "âœ… Load data from sklearn  \n",
    "âœ… Split data for training/testing  \n",
    "âœ… Train a RandomForest model  \n",
    "âœ… Test model accuracy  \n",
    "âœ… Make predictions on new data  \n",
    "\n",
    "### Next steps:\n",
    "ğŸš€ Try different algorithms  \n",
    "ğŸš€ Work with your own datasets  \n",
    "ğŸš€ Learn data visualization  \n",
    "ğŸš€ Explore deep learning  \n",
    "\n",
    "**Happy learning!** ğŸ“âœ¨"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
